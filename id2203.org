#+TITLE: ID2203
#+AUTHOR: Steven Shidi Zhou
#+DESCRIPTION: Lecture notes on Course ID2203 Advanced Distributed Systems
* STRT Lecture 1 - introduction to Distributed Systems
Distributed System definition: A set of *nodes*, connected by a *network*, which appear to its users as a *single* coherent system.
** Core problems in Distributed Systems
*** Consensus/Agreement Problem
  + All nodes/processes /propose/ a /value/.
  + Some nodes (non correct nodes) might crash & stop responding
*** Broadcast Problem
**** Atomic Broadcast
+ A node broadcasts a message
+ If sender correct, all correct nodes deliver message
+ All correct nodes deliver the *same* messages
+ Messages delivered in the *same order*

Atomic broadcast can be used to provide fault tolerance to solve Replicated State Machines (RSM)

Atomic broadcast can be used to solve Consensus! i.e. Every node broadcasts its proposal:
    1. Decide on the *first* received proposal
    2. Messages received in same order, thus all nodes will decide the same value

*Atomic Broadcast is equivalent to Consensus*
** Models of Distributed Systems
*** Asynchronous System Model
+ No bound on time to deliver a message
+ No bound on time to compute
+ Clocks are not synchronized

  *Internet is essentially asynchronous*.

  *Consensus* /cannot/ be solved in asynchronous system if node crashes can happen. you can not find out if a process has failed or just slow.
*** Synchronous System
+ Known bound on time to deliver a message (latency)
+ Known bound on time to compute
+ Known lower and upper bounds in physical clock drift rate.

  Example: Embedded systems(shared clock), Multi-core computers

  *Consensus* is */solvable/* in synchronous system with up to N-1 crashes.
*** Partially synchronous System
+ Initially system is asynchronous
+ Eventually the system becomes synchronous.

  *Consensus is solvable* in partially synchronous system with up to N/2 crashes
*** Timed Asynchronous System
+ No bound on time to deliver a message
+ No bound on time to compute
+ Clocks have known clock drift rate
** Byzantine Faults
Some processes might behave arbitrarily:
+ Sending wrong information
+ Omit message...

*** Byzantine algorithms that tolerate such faults
+ Only tolerate up to 1/3 Byzantine processes
+ Non-Byzantine algorithms can often tolerate 1/2 nodes in the asynchronous model
* STRT Lecture 2 - Basic Abstrctions
** Specification of a Service
*** Correctness
**** Safety
Properties that state that nothing bad *ever* happens. (Often involves the word "never", "at most", "cannot"...)

Safety can only be:
- *satisfied* in infinite time. (you are never safe)
- *violated* in finite time (when the bad happens)

Somtimes called "partial correctness"
**** Liveness
Properties that something good eventually happens. (Often involves the word "eventually" or "must")

Liveness can only be:
- *satisfied* in finite time. (when the good happens)
- *violated* in infinite time. (there is always hope)

Liveness is often just "*Termination*"
*** Models / Assumptions
**** Process failures
***** Crash-stop
Process stops taking steps. (i.e  Not sending messages, nor receiving messages)

Hence, process do not recover
***** Omissions
Process omits sending or receiving messages:
****** Send omission
Not sending messages the process has to send according to its algorithm.
****** Receive omission
Not receiving messages that have been sent to the process
***** Crash-revocery
The process might crash (same as above)

It may *recover* after crashing

Has access to *stable storage*

****** Failure is different in crash-recovery model
A process is *faulty* in an execution if:
- It crashes and *never* recovers, or
- It crashes and recovers *infinitely often* (Unstable)

Hence, a *correct process* may crash and recover *As long as it is a finite number of time*
***** Byzantine failures
A process may behave arbitrarily:
- Sending messages not specified by its algorithm
- Updating its state as not specified by its algorithm

Maybe behave maliciouly, attacking the system
***** Fault-tolerance hierarchy
Byzantine tolerance -> Crash-recovery tolerance -> Omission -> Crash-stop
**** Channel failures
***** Fair-Loss Links
Channels that delivers any message send with non-zero probability (No network partitions)
****** Properties
- *FL1. Fair-loss*: If m is sent infinitely often by P_i to P_j and neither crash, then m is delivered infinitely often by P_j *(Liveness)*
- *FL2. Finite duplication*: If a message m is sent a finite number of times by P_i to P_j, then it is delivered at most a finite number of times by P_j. (i.e. a message can be duplicated a finite4 of times, but cannot be duplicated infinitely many times) *(Liveness)*
- *FL3. No creation*: No message is delivered unless it was sent. *(Safety)*
***** Stubborn Links
Channels delivers an message sent infinitely many times.
****** Properties
- *SL1. Stubborn delivery*: If a correct process P_i sends a message m to a correct process P_j, then P_j delivers m an infinite number of times *(Liveness)*
- *SL2. No creation* If a message m is delivered by some process P_j, then m was previsouly sent m some process P_i. *(Safety)*
****** Correctness
- *SL1. Stubborn delivery*: If process does not crash, it will send every message infinitely many times. Messages will be delivered infinitely many times. Fair-loss link may only drop a (large) fraction.
- *SL2. No creation*: Guaranteed by the Fair-loss link
***** Perfect Links
Channels that delivers any message sent exactly once.
****** Properties
- *PL1. Reliable delivery*: If P_i and P_j are correct, then every message sent by P_i to P_j is eventually delivered by P_j. *(Livenss)*
- *PL2. No duplication*: Every message is delivered at most once. *(Safety)*
- *PL3. No creation*: No message is delivered unless it was sent. *(Safety)*
****** Correctness
- *PL1. Reliable delivery*: Guaranteed by Stubborn link. In fact that Stubborn link will deliver it infinite number of times
- *PL2. No duplication*: Guaranteed b our log mechanism
- *PL3. No creation*: Guaranteed by Stubborn link (which garanteed by its fair-loss link)
***** FIFO Perfect Links (Reliable Links)
****** Properties
- *PL1. Reliable delivery*: If P_i and P_j are correct, then every message sent by P_i to P_j is eventually delivered by P_j. *(Livenss)*
- *PL2. No duplication*: Every message is delivered at most once. *(Safety)*
- *PL3. No creation*: No message is delivered unless it was sent. *(Safety)*
- *FFPL. Ordered delivery*: if m_1 is sent before m_2 by P_i to P_j and m_2 is delivered by P_j then m_1 is delivered by P_j before m_2
****** TCP vs FIFO
- TCP provides reliable delivery of packets.
- TCP reliability is so called "session based"

  In general, FIFO Perfect Links is more strict than TCP
**** Timing Assumptions
***** Asynchronus Model and Causality
****** Asynchronus Systems
- *No timing assumption* on processes and channels
  + Processing time varies arbitarily
  + No bound on transmission time
  + Clocks of different processes are not synchronized
- Reasoning in this model is based on which events may cause other events e.g. *(Causality)*
- *Total order* of event *not observable* locally, no accessto global clocks.
****** Causal Order (Happen before)
- If a occurs before b on the same process, then a -> b
- If a id a send(m) and b deliver(m), then a -> b
- a -> b is transitive: i.e. If a -> b and b -> c then a -> c
****** Equivalence of executions
If two executions F and E have the same collection of events, and their causal order is preserved, F and E are said to be *similar executions*, written F~E

*NOTE*: F and E could have different permutaion of events as long as causality is preserved!

******* Computations:
- ~ is reflexive: i.e. a~a for any execution.
- ~ is symmetric. i.e. If a~b then b~a for anyy executions a and b
- ~ is transitive. i.e. If a~b and b~c, then a~c, for any executions a, b, c
******* Computation theorem gives 2 important results:
- There is no algorithm in the asynchronous system model that can observe the *order* of the sequence of events (that can "see" the time-space diagram, or the trace) for all executions
  + Proof:
    - Assume such an algorithm exists. Assume p knows the order in the final (repeated) configuration
    - Take two distinct similar executions of algorithm preserving causality
    - Computation theorem says their final repeated configurations are the *same*, then the algorithm _cannot_ have observed the actual order of events as *theyy differ*
- The computation theorem does not hold if the model is extended such that each process can read a local *hardware clock*
  + Proof:
    - Similarly, assume a distributed algorithm in which each process reads the local clock each time a local event occurs
    - The final (repeated) configuration of different causalit preserving executions will have different clock values, which would contradict the compuration theorem
****** Synchronous Systems
Model assumes:
- *Synchronous computation*:
  + Known upper bound on how long it takes to perform computation
- *Synchronous communication*:
  + Known upper bound on message transmission delay
- *Synchronous physical Clocks*:
  + Nodes have local physical clock
  + Known upper bound clock-drift rate and clock skew
****** Partial Synchrony
Asynchronous sstem, which *eventually* becomes synchronous. Cannot known when, but in every execution, some bounds eventually will hold.

Your algorithm will have along *enough time* window, where everything behaves nicely (synchrony), so that it can achieve its goal.

Noticed that the time at which a system behaves synchronously is *unknown*:
- To *prove safet properties* we need to *assume* that the system is asynchronous.
- To *prove liveness* we use the *partial synchrony* assumption
***** Logical Clocks
****** Lamport logical clock
Lamport clocks guarantee that:
- If a -> b, then t(a) < t(b)
- If t(a) >= t(b), then not(a -> b)

The happen-before relation is a partial order.

In contrast logical clocks are total:
- Information about non-causalit is *lost*
  + We cannot tell by looking to the timestamps of event a and b whether there is a causal relation between the events, or they are concurrent
****** Vector clock
- if v(a)<v(b), then a -> b in addition to
- if a -> b, then v(a) < v(b)

Cons:
- payload is huge.
- When new process join have to reconfigure and update vector

* STRT Lecture 3 - Failure Detectors
** Implementation of Failure detectors
- periodically exchange heartbeat messages
- timeout based on worst case message round trip
- if timeout, then suspect process
- if received message from suspected node, revise suspicion and increase timeout

** Completeness and Accuracy
*Completeness requirements*: Requirements regrading actually crashed nodes. (when do they have to be detected?)

*Accuracy requirements*: Requirements regrading actually alive nodes. (when are they allowed to be suspected?)

In asynchronous system:
- Is it possible to achieve completeness?
  + es, suspect all processes
- Is it possible to achieve accuracy?
  + Yes, refrain from suspecting any process!
- Is it possible to achieve both?
  + No!

Failure detectors are feasible *only* in synchronous and partiall synchronous systems.
*** Strong Completeness
Every crashed process is *eventually* detected by all correct processes.

There exists a time after which all crashed processes are detected byy all correct processes
*** Weak Completeness
Every crashed process is *eventually* detected by some correct [rpcess]

There  exists a time after which all crashed nodes are detected by some correct nodes.
- Possibly detected by *different* correct nodes
- e.g. 4 process P_1 - P_4, P_3 and P_4 crash, and P_1 only detect P_3, P_2 only detect P_4, this is fine!
*** Strong Accuracy
No correct process is *ever* suspected.

achievable in synchronous systems
*** Weak Accuracy
There exists a correct process which is never suspected by any process (well connected node, useful for leader election)
*** Eventual Strong Accuracy
After some finite time the Failure Detector provides *strong accuracy*
*** Eventual Weak Accuracy
After some finite time the Failure Detector provides *weak accuracy*
** Classes of Failure Detectors
4 detectors with *strong completeness*:
- Synchronous Systems:
  + Perfect Detector (P) -> Strong Accuracy
  + Strong Detector (S) -> Weak Accuracy
- Partially Synchronous Systems:
  + Eventually Perfect Detector (<>P) -> Eventual Strong Accuracy
  + Eventually Strong Detector (<>S) -> Eventual Weak Accuracy

4 detectors with *weak completeness*:
- Synchronous Systems
  + Detector Q -> Strong Accuracy
  + Weak Detector (W) -> Weak Accuracy
- Partially Synchronous Systems:
  + Eventually Detector Q (<>Q) -> Eventual Strong Accuracy
  + Eventually Weak Detector (<>W) -> Eventual Weak Accuracy
*** Perfect Failure Detector - P
**** Properties of P
- *PFD1 (strong completeness)*: Eventually every process that crashes is permanently detected by every correct process. *(Liveness)*
- *PFD2 (strong accuracy)*: If a node p is detected by any node, then p has crashed. *(Safety)*
**** Correctness of P
- *PFD1 (strong completeness)*:
  + A crashed process does not send <heartbeat>
  + Eventually every process will notice the absence of <heartbeat>
- *PFD2 (strong accuracy)*:
  + Assuming local compuration is negligible
  + Maximum time between 2 heartbeats
  + If alive, all process will receive <heartbeat> in time. No inaccuracy
*** Eventually Perfect Failure Detector - <>P
**** Properties of <>P
- *PFD1 (strong completeness)*
- *PFD2 (eventual strong accuracy)*: *Eventually*, no correct process is suspected by any correct process
**** Correctness of <>P
- *PFD1 (strong completeness)*: Same as before
- *PFD2 (eventuall strong accuracy)*:
  + Each time p is inaccurately suspected by a correct q
    - Timeout T is increased at q
    - Eventuallyy system becomes synchronous, and T becomes larger than the unknown bound
    - q will receive <heartbeat> on time, and never suspect p again
** Leader Election
Formally, leader election is a Failure Detector:
- Always suspects all process except one (leader)
- Ensures some properties regarding that process
*** Leader election (LE) which "matches" P
**** Properties of LE
- *LE1 (eventual completeness)*: Eventually every correct process trusts some correct process
- *LE2 (agreement)*: No 2 correct processes trusts different correct processes
- *LE3 (local accuracy)*: If a process is elected leader by P_i, all previously elected leaders by P_i have crashed
*** Eventual leader election (omega) which "matches" <>P
**** Properties of ELE
- *ELD (eventual completeness)*: *Eventually* every correct node trusts some correct node
- *ELD2 (eventual agreement)*: *Eventually* no 2 correct nodes trusts different correct node

Can we elect a recovered process?: Not if it keeps crash-recovering infinitely often
** Reduction
We cay  X \preceq Y if:
- X can be solved given a solution of Y
- Read X is reducible to Y
- Informally problem X is easier or as hard as Y

a relation \preceq is a preorder on a set A.
** Combining Abstractions
*** Fail-stop - Synchronous
- Crash-stop process model
- Perfect links + Perfect failure detector (P)
*** Fail-silent - Asynchronous
- Crash-stop process model
- Perfect links
*** Fail-noisy - Partially synchronous
- Crash-stop process model
- Perfect links +  Eventually Perfect failure detector (<>P)
*** Fail-recovery
- Crash-recovery process model
- Stubborn link + ...
* STRT Lecture 4 - Reliable Broadcast
** Combining Abstractions
*** Combining Abstractions
*** Fail-stop - Synchronous
- Crash-stop process model
- Perfect links + Perfect failure detector (P)
*** Fail-silent - Asynchronous
- Crash-stop process model
- Perfect links
- No access to failure detectors!
*** Fail-noisy - Partially synchronous
- Crash-stop process model
- Perfect links +  Eventually Perfect failure detector (<>P)
- To guarantee safety properties an algorithm has to assume the failure detector inaccurate
- Eventual accuracy is only used to guarantee liveness
*** Fail-recovery
- Crash-recovery process model
- Stubborn link or a persistent links (logs)
- Relies often on a persistent memory to store and retrive crtical info.
** Quorums
- Quorum is any set of majority of processes.
- The algorithms will rely on a majority of processes will not fail
  + f < N/2 (f is the max number of faulty processes, AKA the *resilience* of the algorithm)
** Broadcast Abstractions
*** Reliable broadcast abstractions
- *Best-effort broadcast*: Guarantees reliabilit only if sender is correct
- *Reliable broadcast*: Guarantees reliability independent of whether sender is correct
- *Uniform reliable broadcast*: Also considers behaviour of failed nodes
- *FIFO reliable broadcast*: Reliable broadcast with FIFO delivery order
- *Causal reliable broadcast*: Reliable broadcast with causal delivery order
- *Probabilistic reliable broadcast*:
  + Guarantees reliability with high robability
  + Scales to large number of nodes
- *Total order (atomic) reliable broadcast*: Guarantees reliability and same order of delivery
*** Best-Effort Broadcast (BEB)
Use Perfect channel abstraction ->  Upon <beb Broadcast | m> send message m to all processes (for loop)
**** Properties
- *BED1. Best-effor-Validity*: If P_i and P_j are correct, then any broadcast by P_i is eventually delivered by P_j
- *BEB2. No duplication*: No message delivered more than once
- *BEB3. No creation*: No message delivered unless broadcast
**** Correctness
- If sender does not crash, every other correct process receives message by perfect channels *(Validity)*
- *No creation* & *No duplication* already guaranteed by perfect channels.
*** Reliable Broadcast (RB)
Same as BEB, plus if sender crashes: ensure all or none of the correct nodes get msg
**** Properties
- *RB1 = BEB1. Validity*: If *correct* P_i broadcasts m, P_i itself eventually delivers m
- *RB2 = BEB2. No duplication*
- *RB3 = BEB3. No creation*
- *RB4. Agreement*: If a *correct node delives* m, then every correct process delivers m
**** Fail-Stop: Lazy Reliable Broadcast
Requires perfect failure detector (P) and Beb broadcast

To reliable broadcast m:
- beb boardcast m
- When get beb Deliver
  + save message, and *RB* Deliver message
- If sender s crash, detect and relay message from s to all
***** Correctness of Lazy RB
- *RB1-RB3* satisfied by BEB
- Need to prove *RB4*: If a *correct node delivers* m, then every correct node delivers m.

Assume correct P_k delivers message bcast by P_i:
- If P_i is correct, BEB ensures correct delivery
- If P_i crashes,
  + P_k detects this. (completeness)
  + P_k uses BEB to ensure (BEB1) every correct node gets it
***** Complexity of Lazy RB
Assume N processes:
- *Message complexity*:
  + Best case: O(N) messages
  + Worst case: O(N^2) messages
- *Time complexity*:
  + Best case: 1 time unit
  + Worst case: 2 time units
**** Fail-Silent Eager Reliable Broadcast
uses <>P instead of P. This only affects performance. -> Since we have to assume all processes failed (*worst case senario of Lazy RB*), and we BEB broadcast as soon as you get a message.
*** Uniform Reliable Broadcast
If a *failed process* delivers a message m, then every correct node delivers m.
**** Properties
- *URB1 = RB1*
- *URB3 = RB2*
- *URB3 = RB3*
- *URB4. Uniform Agreement*: For any message m, if a process delivers m, then every correct process delivers m
**** Uniform Eager RB
- Messages and *pending* until all correct processes get it.
  + Collect ACKs from processes that got msg
- Deliver once all correct processes acked
  + Use perfect FD (P)
***** Correctness of Uniform RB
- *No creation* from BEB
- *No duplication* by using "delivered" set
- *Lemma*: If a *correct* process P_i bebDelivers m, then P_i evnetually urbDelivers m
  + Proof:
    - Correct process P_i bebBroadcasts m as soon as it gets m
      + By *BEB1* every correct process gets m and bebBroadcasts m
      + P_i get bebDeliver(m) from every correct process by BEB1
      + By completeness of P, it will not wait for dead nodes forever
        - *canDeliver(m) becomes true and P_i delivers m
****** Validity
If sender is correct, it will by *validity (BEB1)* bebDeliver m.

By the *lemma*, it will eventually urbDeliver(m)
****** Uniform agreement
- Assume some process (possibly failed) URB delivers m
  + Then canDeliver(m) was true, by *accuracy* of P *every* correct process has BEB delivered m
- By *lemma* each of the nodes that BEB delivered m will URB deliver m
**** Fail-Silent Majority-ACK Uniform RB
Assume a majority of correct nodes. Use same algorithm as uniform eager RB, but wait for a majority of nodes has acknowledged m.

- Agreement
  + If a process URB delivers, it got ack from majority
  + In that majorit, one node, p, must be correct
  + p will ensure all correct processes BEB deliver m
    - The correct processes (majority) will ack and URB deliver
- Validity
  + If correct sender sends m
    - All correct nodes BEB deliver m
    - All correct nodes BEB broadcast
    - Sender receives a majorit of acks
    - Sender URB delivers m
** Resilience
The maximum number of fault processes an algorithm can handle.
- *Fail-Silent algorithm* has resilience less than N/2
- *Fail-Stop algorithm* has resilience N-1
** Casual Broadcast
*** Causalit of Messages
- *C1 (FIFO order)*: Some process P_i broadcasts m_1 before broadcasting m_2
- *C2 (Network order)*: Some process P_i delivers m_1 and later broadcasts m_2
- *C3 (Transitivity)*: There is a message m such that m_1 -> m and m -> m_2
*** Reliable Causal Broadcast
**** Properties
- *RB1-RB4* from regular reliable broadcast
- *CB*: If node P_i delivers m, then P_i must deliver ever message causally preceding (->) m before m
*** Uniform Reliable Causal Broadcast
**** Properties
- *URB1-URB4* from uniform reliable broadcast
- *CB*: If node P_i delivers m, then P_i must deliver ever message causally preceding (->) m before m
*** Fail-Silent Waiting Causal Broadcast
Represent past history bu *vector clock (VC)*, Piggback VC and RB broadcast m
- Upon RB delivery of m with attached VC_m
- compare VC_m with local VC
  + Only deliver m once VC_m <= VC
  + Do not deliver if VC_m > VC or VC_m != VC
**** Agreement (Correctness)
- Assume m is co-delivered at correct pi
- pi co-delivered all message causall before m
- Every correct process rb-delivered m and all causall preceding messages (agreement of RB)
- Hence every correct process co-deliver m
*** Other possible orderings
**** Single-source FIFO order
Msgs from same node delivered in order sent
***** Caveat
This formulation does not require delivery of both messages
**** Total Order
Everone delivers everything in exact same order
***** Caveat
This formulation does not require deliver of both messages.

Everyone delivers same order, mabe not send order!
* STRT Lecture 5 - Distributed Shared Memory
** (1, N) Regular register
Validity:
- Read returns *last value written* if
  + Not concurrent with another write, and
  + Not concurrent with a failed write
- Otherwise ma return last or concurrent value
*** Fail-Stop Read one Write all (1, N)
Fail-stop model, use perfect FD (P)
- to write(v):
  + Update local value to v
  + Broadcast v to all
  + Wait for ACK from all correct processes
  + Return
- to read
  + Return local value
**** Correctness
Assume we use BEB broadcast, Perfect links and P

*validity*:
- No concurrent write with the read operations
  + Assume p invokes a read, and v last written value
  + At time of read by p, the write is complete (accurac of P) and p has v stored locally
- Read is concurrent with write of value v, v' the value prior to v
  + Each process store v' before write(v) is invoked
  + At a read is invoked each process either stores v or v'
  + As the writes is concurrent, either value is correct to read
*** Fail-Silent Majority Voting Algorithm
* TODO Lecture 6 -
* TODO Lecture 7 -
* TODO Lecture 8 -
* TODO Lecture 9 -
* TODO Lecture 10 -
* TODO Lecture 11 -
* TODO Lecture 12 -
*
